"""
TDD Cycle 5 - Core System Content Migration Tests
RED Phase: Comprehensive failing tests for core system document migration

Tests for specialized migration of:
- Agent specifications (RESEARCH_AGENTS.md)
- Research methodologies (feynman-first-principles-pkm-research.md) 
- System planning documents (KM-SIMPLIFICATION-*.md)
- Interaction architectures (AGENT-INTERACTION-*.md)

Following TDD methodology: Write failing tests first, then implement to pass.
"""

import pytest
import os
import tempfile
from pathlib import Path
from datetime import datetime
from unittest.mock import Mock, patch
from dataclasses import dataclass
from typing import List, Dict, Any

# Import will fail initially - expected in TDD RED phase
try:
    from src.pkm.core.core_system_migration import (
        CoreSystemMigrationPipeline,
        AgentSpecificationProcessor,
        ResearchMethodologyProcessor,
        SimplificationPlanProcessor,
        CoreSystemMigrationResult,
        AgentSpecification,
        ResearchMethodology,
        SimplificationPlan
    )
except ImportError:
    # Expected during RED phase - tests written before implementation
    CoreSystemMigrationPipeline = None
    AgentSpecificationProcessor = None
    ResearchMethodologyProcessor = None
    SimplificationPlanProcessor = None
    CoreSystemMigrationResult = None
    AgentSpecification = None
    ResearchMethodology = None
    SimplificationPlan = None


@dataclass
class MockCoreSystemDocument:
    """Mock core system document for testing"""
    filename: str
    content: str
    expected_atomic_notes: int
    document_type: str
    expected_elements: List[str]


class TestCoreSystemMigrationPipeline:
    """TDD Cycle 5 tests for core system content migration"""

    @pytest.fixture
    def temp_dirs(self):
        """Create temporary directories for testing"""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            vault_dir = temp_path / "vault"
            docs_dir = temp_path / "docs"
            
            # Create directory structure
            vault_dir.mkdir()
            docs_dir.mkdir()
            (vault_dir / "02-projects" / "pkm-system" / "agents").mkdir(parents=True)
            (vault_dir / "03-resources" / "research" / "methodologies").mkdir(parents=True)
            (vault_dir / "02-projects" / "pkm-system" / "planning").mkdir(parents=True)
            (vault_dir / "permanent" / "notes" / "concepts").mkdir(parents=True)
            
            yield {
                'temp': temp_path,
                'vault': vault_dir,
                'docs': docs_dir
            }

    @pytest.fixture
    def core_system_pipeline(self, temp_dirs):
        """Fixture providing configured CoreSystemMigrationPipeline"""
        if CoreSystemMigrationPipeline is None:
            pytest.skip("CoreSystemMigrationPipeline not implemented yet (TDD RED phase)")
        return CoreSystemMigrationPipeline(vault_path=str(temp_dirs['vault']))

    @pytest.fixture
    def mock_core_system_documents(self, temp_dirs):
        """Create mock core system documents for testing"""
        documents = [
            MockCoreSystemDocument(
                filename="RESEARCH_AGENTS.md",
                content="""---
title: Research Agent System
type: agent-specification
---

# Research Agent System

## Agent Specifications

### Deep Research Agent
**Capabilities:**
- Multi-source validation with confidence scoring
- Academic-level research with peer review standards
- Evidence triangulation across domains
- Systematic bias detection and mitigation

**Workflows:**
1. Query analysis and decomposition
2. Source identification and validation
3. Evidence synthesis and integration
4. Quality assurance and peer review

### Peer Review Agent  
**Capabilities:**
- Systematic quality assessment
- Methodology validation
- Source credibility analysis
- Bias detection across multiple dimensions

**Integration Points:**
- Hooks into research workflow
- Quality gate enforcement
- Automated review triggers

### Synthesis Agent
**Capabilities:**
- Cross-domain knowledge integration
- Framework development (theoretical + practical)
- Pattern identification across research domains
- Insight generation and validation

## System Architecture

### Agent Interaction Patterns
- Sequential processing with quality gates
- Parallel validation for complex queries
- Feedback loops for iterative improvement
- Cross-agent knowledge sharing

### Quality Standards
- Evidence-based methodology requirements
- Multi-source validation thresholds
- Bias detection and mitigation protocols
- Reproducibility and audit trail standards
""",
                expected_atomic_notes=12,
                document_type="agent-specification",
                expected_elements=["Deep Research Agent", "Peer Review Agent", "Synthesis Agent"]
            ),
            MockCoreSystemDocument(
                filename="feynman-first-principles-pkm-research.md",
                content="""---
title: Feynman First Principles PKM Research
type: research-methodology
---

# Feynman First Principles PKM Research

## Methodology Overview

This research applies the Feynman Technique and first principles thinking to Personal Knowledge Management (PKM) system design.

## Core Principles

### First Principles Analysis
1. **Fundamental Question**: What is the simplest way to capture, organize, and retrieve knowledge?
2. **Assumptions to Question**: Traditional hierarchical organization, linear note-taking, manual categorization
3. **Core Components**: Capture mechanism, organization system, retrieval interface, synthesis tools

### Feynman Technique Application
1. **Explain in Simple Terms**: PKM system = digital brain that learns your thinking patterns
2. **Identify Knowledge Gaps**: Where do current systems fail? Fragmentation, search difficulty, context loss
3. **Simplify and Analogize**: Like a librarian who remembers exactly where everything is and how it connects
4. **Test Understanding**: Can a non-technical person use and benefit from the system?

## Research Findings

### Complexity Reduction Principles
- **Atomic Information Units**: Break knowledge into smallest meaningful pieces
- **Automatic Classification**: System learns from user behavior rather than requiring manual categorization
- **Context-Aware Retrieval**: Surface information based on current context and past connections
- **Progressive Disclosure**: Show simple interface initially, reveal complexity as needed

### Cognitive Load Minimization
- **Single Capture Point**: One place for all information input
- **Zero-Decision Capture**: No categorization required during input
- **Intelligent Suggestions**: System proposes connections and organization
- **Natural Language Interface**: Interact using normal language, not system-specific commands

## Implementation Guidelines

### ELI5 Design Principle
Every feature must be explainable to a five-year-old:
- "The computer remembers everything you tell it"
- "It connects ideas that go together"
- "It helps you find things when you need them"
- "It shows you new ideas based on what you're thinking about"

### Validation Methodology
1. **User Testing**: Can new users accomplish basic tasks without training?
2. **Cognitive Load Measurement**: Time to capture vs. time to retrieve information
3. **Learning Curve Analysis**: How quickly do users become proficient?
4. **Long-term Adoption**: Do users continue using the system after initial enthusiasm?
""",
                expected_atomic_notes=15,
                document_type="research-methodology",
                expected_elements=["First Principles Analysis", "Feynman Technique Application", "ELI5 Design Principle"]
            ),
            MockCoreSystemDocument(
                filename="KM-SIMPLIFICATION-PLAN.md", 
                content="""---
title: Knowledge Management Simplification Plan
type: simplification-plan
---

# Knowledge Management Simplification Plan

## Simplification Philosophy

Transform complex PKM systems into intuitive, effortless knowledge tools following the principle: "Advanced technology should feel like magic, not machinery."

## Current State Analysis

### Complexity Sources
1. **Multiple Entry Points**: Users must choose between different capture methods
2. **Manual Organization**: Requires decision-making during knowledge input
3. **System-Specific Syntax**: Learning curve for linking, tagging, formatting
4. **Cognitive Overhead**: Mental energy spent on system mechanics vs. thinking

### User Pain Points
- "Where should I put this?"
- "How do I find what I saved last week?"
- "Why is this system fighting me?"
- "I spend more time organizing than thinking"

## Simplification Strategy

### Phase 1: Unified Capture
**Goal**: Single point of entry for all knowledge
**Implementation**:
- One capture interface for all content types
- Automatic format detection and conversion
- Context-aware suggestions without mandatory decisions
- Background processing of captured content

### Phase 2: Invisible Organization
**Goal**: System organizes without user involvement
**Implementation**:
- Machine learning classification based on content and usage patterns
- Automatic relationship detection between ideas
- Dynamic categorization that evolves with use
- Progressive organization refinement

### Phase 3: Contextual Retrieval
**Goal**: Information surfaces when needed
**Implementation**:
- Proactive suggestions based on current work
- Context-aware search that understands intent
- Relationship mapping for serendipitous discovery
- Natural language query processing

## Design Principles

### Principle 1: Zero-Friction Capture
- Capture should be faster than forgetting
- No decisions required during input
- Accept any format, clean up automatically
- Context preservation without user effort

### Principle 2: Invisible Complexity
- Advanced features hidden until needed
- Progressive disclosure based on user sophistication
- Power user features available but not prominent
- System complexity grows with user needs

### Principle 3: Effortless Retrieval
- Information appears before you think to search for it
- Natural language queries understand intent
- Visual connections show unexpected relationships
- Browsing should feel like thought itself

## Success Metrics

### User Experience Metrics
- Time from thought to capture: < 5 seconds
- Time from query to answer: < 3 seconds  
- Days of regular use before abandonment: > 30
- User satisfaction score: > 4.5/5

### System Performance Metrics
- Capture accuracy: > 95%
- Auto-categorization accuracy: > 90%
- Search relevance score: > 90%
- System response time: < 200ms
""",
                expected_atomic_notes=10,
                document_type="simplification-plan",
                expected_elements=["Zero-Friction Capture", "Invisible Complexity", "Effortless Retrieval"]
            )
        ]
        
        # Write mock documents to temp directory
        for doc in documents:
            doc_path = temp_dirs['docs'] / doc.filename
            doc_path.write_text(doc.content, encoding='utf-8')
        
        return documents

    # ===============================================================================
    # CATEGORY A: AGENT SPECIFICATION PROCESSING TESTS
    # ===============================================================================

    def test_migrates_research_agents_specification(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should migrate RESEARCH_AGENTS.md with agent-specific processing"""
        # Arrange
        agents_doc = next(doc for doc in mock_core_system_documents if doc.filename == "RESEARCH_AGENTS.md")
        agents_file = temp_dirs['docs'] / agents_doc.filename
        
        # Act
        result = core_system_pipeline.migrate_agent_specification(str(agents_file))
        
        # Assert
        assert result.success is True
        assert result.agents_identified >= 3  # Deep Research, Peer Review, Synthesis
        assert result.capabilities_extracted >= 10
        assert result.workflows_mapped >= 3
        assert result.integration_points >= 2
        
        # Verify target location
        target_file = temp_dirs['vault'] / "02-projects" / "pkm-system" / "agents" / "RESEARCH_AGENTS.md"
        assert target_file.exists()

    def test_extracts_agent_capabilities_as_atomic_notes(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should extract agent capabilities as atomic notes"""
        # Arrange
        agents_doc = next(doc for doc in mock_core_system_documents if doc.filename == "RESEARCH_AGENTS.md")
        agents_file = temp_dirs['docs'] / agents_doc.filename
        
        # Act
        result = core_system_pipeline.extract_agent_capabilities(str(agents_file))
        
        # Assert
        assert result.success is True
        assert len(result.capability_atomic_notes) >= 8
        
        # Verify capability-specific metadata
        for capability_note in result.capability_atomic_notes:
            assert capability_note.type == "agent-capability"
            assert capability_note.agent_name is not None
            assert len(capability_note.implementation_details) > 0
            assert capability_note.integration_requirements is not None

    def test_maps_agent_interaction_workflows(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should map agent interaction patterns and workflows"""
        # Arrange
        agents_doc = next(doc for doc in mock_core_system_documents if doc.filename == "RESEARCH_AGENTS.md")
        agents_file = temp_dirs['docs'] / agents_doc.filename
        
        # Act
        result = core_system_pipeline.map_agent_workflows(str(agents_file))
        
        # Assert
        assert result.success is True
        assert len(result.workflow_maps) >= 3
        assert result.interaction_patterns_identified >= 4
        
        # Verify workflow mapping details
        for workflow in result.workflow_maps:
            assert workflow.agent_name in ["Deep Research Agent", "Peer Review Agent", "Synthesis Agent"]
            assert len(workflow.steps) >= 3
            assert workflow.quality_gates is not None

    # ===============================================================================
    # CATEGORY B: RESEARCH METHODOLOGY PROCESSING TESTS
    # ===============================================================================

    def test_processes_feynman_research_methodology(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should process Feynman methodology document with research-specific extraction"""
        # Arrange
        research_doc = next(doc for doc in mock_core_system_documents if doc.filename == "feynman-first-principles-pkm-research.md")
        research_file = temp_dirs['docs'] / research_doc.filename
        
        # Act
        result = core_system_pipeline.migrate_research_methodology(str(research_file))
        
        # Assert
        assert result.success is True
        assert result.methodology_type == "feynman-first-principles"
        assert result.principles_extracted >= 8
        assert result.examples_created >= 5
        assert result.eli5_summaries >= 3
        
        # Verify target location in resources
        target_file = temp_dirs['vault'] / "03-resources" / "research" / "methodologies" / "feynman-first-principles-pkm-research.md"
        assert target_file.exists()

    def test_extracts_research_principles_as_atomic_notes(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should extract research principles with Feynman validation"""
        # Arrange
        research_doc = next(doc for doc in mock_core_system_documents if doc.filename == "feynman-first-principles-pkm-research.md")
        research_file = temp_dirs['docs'] / research_doc.filename
        
        # Act
        result = core_system_pipeline.extract_research_principles(str(research_file))
        
        # Assert
        assert result.success is True
        assert len(result.principle_atomic_notes) >= 8
        
        # Verify Feynman-specific validation
        for principle_note in result.principle_atomic_notes:
            assert principle_note.type == "research-principle"
            assert principle_note.feynman_validated is True
            assert len(principle_note.eli5_explanation) >= 50
            assert principle_note.complexity_level in ["simple", "intermediate", "advanced"]

    def test_creates_eli5_summaries_for_complex_concepts(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should create ELI5 summaries for complex research concepts"""
        # Arrange
        research_doc = next(doc for doc in mock_core_system_documents if doc.filename == "feynman-first-principles-pkm-research.md")
        research_file = temp_dirs['docs'] / research_doc.filename
        
        # Act
        result = core_system_pipeline.create_eli5_summaries(str(research_file))
        
        # Assert
        assert result.success is True
        assert len(result.eli5_summaries) >= 3
        
        # Verify ELI5 quality standards
        for summary in result.eli5_summaries:
            assert len(summary.simple_explanation) >= 100
            assert summary.uses_analogies is True
            assert summary.avoids_jargon is True
            assert summary.comprehension_level <= 5  # 5th grade reading level

    # ===============================================================================
    # CATEGORY C: SIMPLIFICATION PLAN PROCESSING TESTS
    # ===============================================================================

    def test_processes_simplification_plan_with_workflow_extraction(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should process KM simplification plan with workflow and principle extraction"""
        # Arrange
        plan_doc = next(doc for doc in mock_core_system_documents if doc.filename == "KM-SIMPLIFICATION-PLAN.md")
        plan_file = temp_dirs['docs'] / plan_doc.filename
        
        # Act
        result = core_system_pipeline.migrate_simplification_plan(str(plan_file))
        
        # Assert
        assert result.success is True
        assert result.principles_identified >= 3
        assert result.phases_mapped >= 3
        assert result.metrics_extracted >= 8
        assert result.pain_points_identified >= 4
        
        # Verify target location in planning
        target_file = temp_dirs['vault'] / "02-projects" / "pkm-system" / "planning" / "KM-SIMPLIFICATION-PLAN.md"
        assert target_file.exists()

    def test_extracts_design_principles_with_implementation_guidance(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should extract design principles with actionable implementation guidance"""
        # Arrange
        plan_doc = next(doc for doc in mock_core_system_documents if doc.filename == "KM-SIMPLIFICATION-PLAN.md")
        plan_file = temp_dirs['docs'] / plan_doc.filename
        
        # Act
        result = core_system_pipeline.extract_design_principles(str(plan_file))
        
        # Assert
        assert result.success is True
        assert len(result.principle_atomic_notes) >= 3
        
        # Verify principle-specific metadata
        for principle_note in result.principle_atomic_notes:
            assert principle_note.type == "design-principle"
            assert principle_note.implementation_guidance is not None
            assert len(principle_note.success_metrics) > 0
            assert principle_note.complexity_reduction_score >= 0.0

    def test_maps_simplification_phases_with_dependencies(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should map simplification phases with clear dependencies and metrics"""
        # Arrange
        plan_doc = next(doc for doc in mock_core_system_documents if doc.filename == "KM-SIMPLIFICATION-PLAN.md")
        plan_file = temp_dirs['docs'] / plan_doc.filename
        
        # Act
        result = core_system_pipeline.map_simplification_phases(str(plan_file))
        
        # Assert
        assert result.success is True
        assert len(result.phase_maps) >= 3
        
        # Verify phase mapping details
        for phase in result.phase_maps:
            assert phase.phase_name in ["Unified Capture", "Invisible Organization", "Contextual Retrieval"]
            assert len(phase.implementation_steps) >= 3
            assert phase.success_metrics is not None
            assert phase.dependencies is not None

    # ===============================================================================
    # CATEGORY D: BATCH PROCESSING AND INTEGRATION TESTS
    # ===============================================================================

    def test_processes_all_core_system_documents_with_appropriate_routing(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should process all core system documents with appropriate domain-specific routing"""
        # Arrange
        docs_dir = str(temp_dirs['docs'])
        
        # Act
        result = core_system_pipeline.migrate_core_system_documents(docs_dir)
        
        # Assert
        assert result.success is True
        assert result.files_migrated == len(mock_core_system_documents)
        assert result.agent_specs_processed >= 1
        assert result.research_methodologies_processed >= 1
        assert result.simplification_plans_processed >= 1
        
        # Verify proper PARA categorization
        agents_files = list((temp_dirs['vault'] / "02-projects" / "pkm-system" / "agents").glob("*.md"))
        research_files = list((temp_dirs['vault'] / "03-resources" / "research" / "methodologies").glob("*.md"))
        planning_files = list((temp_dirs['vault'] / "02-projects" / "pkm-system" / "planning").glob("*.md"))
        
        assert len(agents_files) >= 1
        assert len(research_files) >= 1  
        assert len(planning_files) >= 1

    def test_creates_comprehensive_cross_references_between_core_documents(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should create meaningful cross-references between related core system documents"""
        # Arrange
        docs_dir = str(temp_dirs['docs'])
        
        # Act
        result = core_system_pipeline.migrate_core_system_documents(docs_dir)
        
        # Assert
        assert result.cross_references_created >= 10
        assert result.domain_connections_mapped >= 5
        
        # Verify specific cross-reference patterns
        atomic_notes = result.all_atomic_notes_created
        agent_notes = [note for note in atomic_notes if note.type == "agent-capability"]
        principle_notes = [note for note in atomic_notes if note.type in ["research-principle", "design-principle"]]
        
        # Agent capabilities should reference research principles
        agent_principle_links = 0
        for agent_note in agent_notes:
            for principle_note in principle_notes:
                if principle_note.id in agent_note.bidirectional_links:
                    agent_principle_links += 1
        
        assert agent_principle_links >= 3

    def test_maintains_quality_standards_for_diverse_content_types(self, core_system_pipeline, temp_dirs, mock_core_system_documents):
        """Should maintain consistent quality standards across different content types"""
        # Arrange
        docs_dir = str(temp_dirs['docs'])
        
        # Act
        result = core_system_pipeline.migrate_core_system_documents(docs_dir)
        
        # Assert
        assert result.overall_quality_score >= 0.85
        
        # Verify quality distribution across content types
        atomic_notes_by_type = {}
        for note in result.all_atomic_notes_created:
            note_type = note.type
            if note_type not in atomic_notes_by_type:
                atomic_notes_by_type[note_type] = []
            atomic_notes_by_type[note_type].append(note)
        
        # Each content type should have quality atomic notes
        for note_type, notes in atomic_notes_by_type.items():
            avg_quality = sum(note.quality_score for note in notes) / len(notes)
            assert avg_quality >= 0.8, f"Quality too low for {note_type}: {avg_quality}"

    # ===============================================================================
    # CATEGORY E: DOMAIN-SPECIFIC PROCESSOR TESTS
    # ===============================================================================

    def test_agent_specification_processor_identifies_system_components(self):
        """Should identify agents, capabilities, workflows, and integration points"""
        if AgentSpecificationProcessor is None:
            pytest.skip("AgentSpecificationProcessor not implemented yet (TDD RED phase)")
        
        # Arrange
        processor = AgentSpecificationProcessor()
        agent_text = """
        ## Deep Research Agent
        **Capabilities:** Multi-source validation, Evidence triangulation
        **Workflows:** 1. Query analysis 2. Source validation 3. Synthesis
        **Integration:** Hooks into research workflow, Quality gates
        """
        
        # Act
        result = processor.process_agent_specification(agent_text)
        
        # Assert
        assert len(result.agents) >= 1
        assert len(result.capabilities) >= 2
        assert len(result.workflows) >= 1
        assert len(result.integration_points) >= 2

    def test_research_methodology_processor_applies_feynman_technique(self):
        """Should apply Feynman technique validation to research concepts"""
        if ResearchMethodologyProcessor is None:
            pytest.skip("ResearchMethodologyProcessor not implemented yet (TDD RED phase)")
        
        # Arrange
        processor = ResearchMethodologyProcessor()
        research_text = """
        ## First Principles Analysis
        Fundamental question: What is the simplest way to capture knowledge?
        Core components: Capture, organize, retrieve, synthesize
        
        ## ELI5 Principle  
        The computer remembers everything you tell it and connects ideas that go together.
        """
        
        # Act
        result = processor.process_research_methodology(research_text)
        
        # Assert
        assert len(result.principles) >= 2
        assert len(result.eli5_summaries) >= 1
        assert result.feynman_validation_applied is True

    def test_simplification_plan_processor_extracts_actionable_phases(self):
        """Should extract simplification phases with implementation guidance"""
        if SimplificationPlanProcessor is None:
            pytest.skip("SimplificationPlanProcessor not implemented yet (TDD RED phase)")
        
        # Arrange
        processor = SimplificationPlanProcessor()
        plan_text = """
        ## Phase 1: Unified Capture
        Goal: Single point of entry
        Implementation: One interface, automatic detection, context-aware suggestions
        
        ## Principle: Zero-Friction Capture
        Capture should be faster than forgetting
        Success metric: < 5 seconds from thought to capture
        """
        
        # Act
        result = processor.process_simplification_plan(plan_text)
        
        # Assert
        assert len(result.phases) >= 1
        assert len(result.principles) >= 1
        assert len(result.success_metrics) >= 1


# ===============================================================================
# INTEGRATION TESTS WITH REAL CORE SYSTEM DOCUMENTS
# ===============================================================================

class TestRealCoreSystemDocumentMigration:
    """Integration tests using real core system documents from docs/"""
    
    @pytest.fixture
    def temp_dirs(self):
        """Create temporary directories for testing"""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            vault_dir = temp_path / "vault"
            vault_dir.mkdir()
            yield {'temp': temp_path, 'vault': vault_dir}
    
    @pytest.fixture
    def core_system_pipeline(self, temp_dirs):
        """Fixture providing configured CoreSystemMigrationPipeline"""
        if CoreSystemMigrationPipeline is None:
            pytest.skip("CoreSystemMigrationPipeline not implemented yet (TDD RED phase)")
        return CoreSystemMigrationPipeline(vault_path=str(temp_dirs['vault']))
    
    @pytest.fixture
    def real_docs_available(self):
        """Check if real core system documents exist"""
        required_docs = [
            "docs/RESEARCH_AGENTS.md",
            "docs/feynman-first-principles-pkm-research.md", 
            "docs/KM-SIMPLIFICATION-PLAN.md"
        ]
        
        available_docs = []
        for doc_path in required_docs:
            if Path(doc_path).exists():
                available_docs.append(Path(doc_path))
        
        if len(available_docs) == 0:
            pytest.skip("No real core system documents available for testing")
            
        return available_docs
    
    def test_processes_real_research_agents_specification(self, core_system_pipeline, real_docs_available):
        """Should successfully process the real RESEARCH_AGENTS.md file"""
        # Arrange
        agents_file = next((doc for doc in real_docs_available if doc.name == "RESEARCH_AGENTS.md"), None)
        if not agents_file:
            pytest.skip("RESEARCH_AGENTS.md not found in docs/")
        
        # Act
        result = core_system_pipeline.migrate_agent_specification(str(agents_file))
        
        # Assert
        assert result.success is True
        assert result.agents_identified >= 2, "Should identify at least 2 agents from real specification"
        assert result.overall_quality_score >= 0.7, "Real document processing should meet quality standards"

    def test_processes_real_feynman_research_methodology(self, core_system_pipeline, real_docs_available):
        """Should successfully process the real feynman research methodology file"""
        # Arrange
        feynman_file = next((doc for doc in real_docs_available if "feynman" in doc.name.lower()), None)
        if not feynman_file:
            pytest.skip("Feynman research methodology file not found in docs/")
        
        # Act
        result = core_system_pipeline.migrate_research_methodology(str(feynman_file))
        
        # Assert
        assert result.success is True
        assert result.principles_extracted >= 5, "Should extract at least 5 principles from real methodology"
        assert result.overall_quality_score >= 0.7, "Real methodology processing should meet quality standards"


# These tests should ALL FAIL initially (TDD RED phase)
# Implementation comes next (GREEN phase)  
# Then refactoring for optimization (REFACTOR phase)